{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae882bb-a7f6-44cb-a807-dbda83c33ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai import gemini\n",
    "from inspect import getsource\n",
    "from smells import smells\n",
    "import subprocess\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11339490-c227-47c7-bcb3-43ee60eb5de9",
   "metadata": {},
   "source": [
    "# 1. configuration\n",
    "## select model to generate the unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40acd822-8441-470b-82b8-b0e428852d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-28 11:50:19.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgenai.gemini\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1musing publishers/google/models/gemini-2.5-pro-preview-03-25, temp 1.0, top_p 1, max_output_tokens 65535\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "m = gemini.GeminiModel(max_output_tokens=1024*64-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa63f56-553f-4f19-91ff-23fb605b0f1b",
   "metadata": {},
   "source": [
    "## define the package and function for which to generate test\n",
    "\n",
    "- it must be importable.\n",
    "- we use funcs in file `misc.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f67a7d6-b84d-4d20-a2c1-a861df79906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_name = 'misc'\n",
    "#function_name = 'isprime'\n",
    "function_name = 'cauchy'\n",
    "#function_name = 'change_money'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91a490-fcdf-477f-bbea-c4fe6ea2b712",
   "metadata": {},
   "source": [
    "# 2. create unit test for target function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0296ca-2af1-43e6-a62b-c10681385231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def cauchy(x, y):\n",
      "    r = np.subtract.outer(x, y) \n",
      "    if np.sum(r==0)>0:\n",
      "        raise ValueError(\"division by zero\")\n",
      "        \n",
      "    return 1/r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exec(f'from modules.{module_name} import {function_name}')\n",
    "function = eval(function_name)\n",
    "print (getsource(function))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea0ddf-17af-41be-8220-c24f3ee85ec8",
   "metadata": {},
   "source": [
    "## create generation prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4311384-e29f-4059-8940-67337691fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_unittest = \"\"\"\n",
    "generate a unit test for this python function which is accessible with the following import\n",
    "\n",
    "{import_def}\n",
    "\n",
    "<FUNCTION_DEFINITION>\n",
    "{function_src}\n",
    "</FUNCTION_DEFINITION>\n",
    "\n",
    "- enclose the unit test class together with all necessary imports within an xml tag <UNITTEST_CLASS> \n",
    "- include docstrings of all functions, classes and modules\n",
    "- the code within <UNITTEST_CLASS> must be executable as is, do not include triple quotes or other markings\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_unittest.format(import_def = f\"from modules.{module_name} import {function_name}\",\n",
    "                                function_src=getsource(function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f09064-b14a-4a1c-91c0-97f78b8b6ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generate a unit test for this python function which is accessible with the following import\n",
      "\n",
      "from modules.misc import cauchy\n",
      "\n",
      "<FUNCTION_DEFINITION>\n",
      "def cauchy(x, y):\n",
      "    r = np.subtract.outer(x, y) \n",
      "    if np.sum(r==0)>0:\n",
      "        raise ValueError(\"division by zero\")\n",
      "        \n",
      "    return 1/r\n",
      "\n",
      "</FUNCTION_DEFINITION>\n",
      "\n",
      "- enclose the unit test class together with all necessary imports within an xml tag <UNITTEST_CLASS> \n",
      "- include docstrings of all functions, classes and modules\n",
      "- the code within <UNITTEST_CLASS> must be executable as is, do not include triple quotes or other markings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f3f0d-4813-41e0-84c6-d7b2a96260cc",
   "metadata": {},
   "source": [
    "## generate unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bb1ceed-22aa-4567-a95f-1a045e338110",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = m.generate_text(prompt)\n",
    "a = r['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8ff785d-5634-49b9-93ed-183bb2ed7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = r['logprobs']\n",
    "if l is not None:\n",
    "    probs = [np.exp(i.log_probability) for i in l.chosen_candidates]\n",
    "    plt.title(f'probabilities for {len(probs)} output tokens\\nshowing percentile >2.5%')\n",
    "    plt.hist(probs, density=True, bins=100);\n",
    "    plt.grid()\n",
    "    plt.xlabel('probability')\n",
    "    plt.ylabel('frequency')\n",
    "    \n",
    "    a,b = np.percentile(probs, [2.5,100])\n",
    "    \n",
    "    plt.xlim(a,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f78b7-8172-45ac-9073-b9d8eb232aa4",
   "metadata": {},
   "source": [
    "## extract unit test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f37c390e-0663-4b24-baf2-a4ded793d981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python3\n",
      "\"\"\"\n",
      "Unit tests for the cauchy function from modules.misc.\n",
      "\"\"\"\n",
      "\n",
      "import unittest\n",
      "import numpy as np\n",
      "\n",
      "# Assume the function is accessible via this import path\n",
      "# If 'modules.misc' cannot be found directly, ensure the PYTHONPATH is set correctly\n",
      "# or adjust the import based on the actual project structure.\n",
      "try:\n",
      "    from modules.misc import cauchy\n",
      "except ImportError:\n",
      "    # Provide a dummy implementation if the module is not found,\n",
      "    # allowing the test structure to be generated, but tests will fail\n",
      "    # if the actual module isn't available during execution.\n",
      "    # This part might be adjusted or removed depending on the testing environment.\n",
      "    print(\"Warning: 'modules.misc.cauchy' not found. Using dummy implementation.\")\n",
      "    def cauchy(x, y):\n",
      "        \"\"\"Dummy cauchy function if import fails.\"\"\"\n",
      "        if not isinstance(x, np.ndarray): x = np.array(x)\n",
      "        if not isinstance(y, np.ndarray): y = np.array(y)\n",
      "        r = np.subtract.outer(x, y)\n",
      "        if np.any(r == 0):\n",
      "             raise ValueError(\"division by zero\")\n",
      "        return 1.0 / r\n",
      "\n",
      "\n",
      "class TestCauchyFunction(unittest.TestCase):\n",
      "    \"\"\"\n",
      "    Test suite for the cauchy function.\n",
      "    \"\"\"\n",
      "\n",
      "    def test_cauchy_standard_case(self):\n",
      "        \"\"\"\n",
      "        Test cauchy function with valid inputs, no zero differences.\n",
      "        \"\"\"\n",
      "        x = np.array([1, 2])\n",
      "        y = np.array([3, 4])\n",
      "        # Expected result:\n",
      "        # r = [[1-3, 1-4], [2-3, 2-4]] = [[-2, -3], [-1, -2]]\n",
      "        # 1/r = [[-1/2, -1/3], [-1/1, -1/2]] = [[-0.5, -1/3], [-1.0, -0.5]]\n",
      "        expected_output = np.array([\n",
      "            [-0.5, -1/3.],\n",
      "            [-1.0, -0.5]\n",
      "        ])\n",
      "        actual_output = cauchy(x, y)\n",
      "        np.testing.assert_allclose(\n",
      "            actual_output,\n",
      "            expected_output,\n",
      "            rtol=1e-5,\n",
      "            atol=1e-8,\n",
      "            err_msg=\"Standard case calculation failed.\"\n",
      "        )\n",
      "\n",
      "    def test_cauchy_zero_difference_error(self):\n",
      "        \"\"\"\n",
      "        Test cauchy function raises ValueError when a difference is zero.\n",
      "        \"\"\"\n",
      "        x = np.array([1, 2])\n",
      "        y = np.array([3, 1]) # Difference 1-1 = 0 should occur\n",
      "        with self.assertRaisesRegex(ValueError, \"division by zero\"):\n",
      "            cauchy(x, y)\n",
      "\n",
      "    def test_cauchy_different_shapes(self):\n",
      "        \"\"\"\n",
      "        Test cauchy function with inputs of different shapes.\n",
      "        \"\"\"\n",
      "        x = np.array([5])\n",
      "        y = np.array([1, 2, 3])\n",
      "        # Expected result:\n",
      "        # r = [[5-1, 5-2, 5-3]] = [[4, 3, 2]]\n",
      "        # 1/r = [[1/4, 1/3, 1/2]] = [[0.25, 1/3, 0.5]]\n",
      "        expected_output = np.array([[0.25, 1/3., 0.5]])\n",
      "        actual_output = cauchy(x, y)\n",
      "        np.testing.assert_allclose(\n",
      "            actual_output,\n",
      "            expected_output,\n",
      "            rtol=1e-5,\n",
      "            atol=1e-8,\n",
      "            err_msg=\"Different shapes case calculation failed.\"\n",
      "        )\n",
      "\n",
      "    def test_cauchy_empty_input(self):\n",
      "        \"\"\"\n",
      "        Test cauchy function with one empty input array.\n",
      "        \"\"\"\n",
      "        x = np.array([])\n",
      "        y = np.array([1, 2])\n",
      "        expected_output = np.empty((0, 2)) # Result of outer on (0,) and (2,)\n",
      "        actual_output = cauchy(x, y)\n",
      "        np.testing.assert_array_equal(\n",
      "            actual_output,\n",
      "            expected_output,\n",
      "            err_msg=\"Empty input array (x) case failed.\"\n",
      "        )\n",
      "\n",
      "        x = np.array([1, 2])\n",
      "        y = np.array([])\n",
      "        expected_output = np.empty((2, 0)) # Result of outer on (2,) and (0,)\n",
      "        actual_output = cauchy(x, y)\n",
      "        np.testing.assert_array_equal(\n",
      "            actual_output,\n",
      "            expected_output,\n",
      "            err_msg=\"Empty input array (y) case failed.\"\n",
      "        )\n",
      "\n",
      "    def test_cauchy_both_empty_input(self):\n",
      "        \"\"\"\n",
      "        Test cauchy function with both input arrays empty.\n",
      "        \"\"\"\n",
      "        x = np.array([])\n",
      "        y = np.array([])\n",
      "        expected_output = np.empty((0, 0)) # Result of outer on (0,) and (0,)\n",
      "        actual_output = cauchy(x, y)\n",
      "        np.testing.assert_array_equal(\n",
      "            actual_output,\n",
      "            expected_output,\n",
      "            err_msg=\"Both empty input arrays case failed.\"\n",
      "        )\n",
      "\n",
      "    def test_cauchy_scalar_like_input(self):\n",
      "        \"\"\"\n",
      "        Test cauchy function with scalar-like numpy arrays.\n",
      "        \"\"\"\n",
      "        x = np.array([5])\n",
      "        y = np.array([3])\n",
      "        # Expected result:\n",
      "        # r = [[5-3]] = [[2]]\n",
      "        # 1/r = [[1/2]] = [[0.5]]\n",
      "        expected_output = np.array([[0.5]])\n",
      "        actual_output = cauchy(x, y)\n",
      "        np.testing.assert_allclose(\n",
      "            actual_output,\n",
      "            expected_output,\n",
      "            rtol=1e-5,\n",
      "            atol=1e-8,\n",
      "            err_msg=\"Scalar-like input case calculation failed.\"\n",
      "        )\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    \"\"\"\n",
      "    Run the test suite if this script is executed directly.\n",
      "    \"\"\"\n",
      "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_start = a.find('<UNITTEST_CLASS>')+17\n",
    "f_end = a.find('</UNITTEST_CLASS>')\n",
    "\n",
    "unittest_src = a[f_start:f_end]\n",
    "print(unittest_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8447fb-8a9e-4906-a0fa-2c7703bca676",
   "metadata": {},
   "source": [
    "## run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f9ab126-dfe4-4c2a-bae6-8be4da2c9212",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'unittest.main()' in unittest_src:\n",
    "    unittest_src += \"\"\"\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "    \"\"\"\n",
    "\n",
    "with open('file_with_tests.py', 'w') as f:\n",
    "    f.write(unittest_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "658eb26c-8be7-4fc8-b0f4-16288a2448c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = [sys.executable, 'file_with_tests.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f340c2d-3c32-478c-a3db-767292610bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(\n",
    "    command,\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    check=False, # Recommended to automatically check for errors\n",
    "    encoding='utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66bcb817-a747-4571-b846-8d3975699de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d57eb1ef-184e-489d-8bb1-70236161bba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.015s\n",
      "\n",
      "OK\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.001s\n",
      "\n",
      "OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed58fd84-b1df-4c02-b8de-e0dfa6affc00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3115b74-c581-42cc-bc80-3c04c8ae244d",
   "metadata": {},
   "source": [
    "# 3. create counter example for unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76938d6a-5d63-4588-be8b-3a9ae3561905",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "create a version of this function that returns an incorrect answer by changing \n",
    "its logic with common programming mistakes.\n",
    "\n",
    "<FUNCTION_DEFINITION>\n",
    "{getsource(function)}\n",
    "</FUNCTION_DEFINITION>\n",
    "\n",
    "follow strictly this instructions:\n",
    "\n",
    "- the new function must always return an incorrect answer.\n",
    "- don't hard code specific values, determine algorithmically in what ciscumstances \n",
    "the function should return an incorrect value\n",
    "- use the same function name\n",
    "- enclose the new function together with all necessary imports within an xml tag <COUNTER_EXAMPLE> \n",
    "- the code within <COUNTER_EXAMPLE> must be executable as is, do not include triple quotes or other markings\n",
    "- include docstrings of all functions, classes and modules\n",
    "\"\"\"\n",
    "\n",
    "r = m.generate_text(prompt)\n",
    "a = r['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20f154b0-3683-4b06-83d7-388485b9ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import numpy as np\n",
      "\n",
      "def cauchy(x, y):\n",
      "    \"\"\"\n",
      "    Calculates an incorrect Cauchy-like matrix due to a logical error.\n",
      "\n",
      "    This version introduces a common mistake by replacing the subtraction\n",
      "    operation, intended for the standard Cauchy matrix definition (1 / (x_i - y_j)),\n",
      "    with an addition operation. As a result, it incorrectly computes\n",
      "    1 / (x_i + y_j) for each pair of elements from input arrays x and y.\n",
      "    This ensures the returned matrix is computationally incorrect relative\n",
      "    to the standard definition.\n",
      "\n",
      "    Args:\n",
      "        x: A numpy array representing the first set of values (e.g., x_i).\n",
      "        y: A numpy array representing the second set of values (e.g., y_j).\n",
      "\n",
      "    Returns:\n",
      "        A numpy array where the element (i, j) is incorrectly\n",
      "        calculated as 1 / (x[i] + y[j]).\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If any pair (x[i], y[j]) sums to zero (x[i] + y[j] == 0),\n",
      "                    as this would lead to division by zero in the incorrect\n",
      "                    calculation performed by this function. Note that this\n",
      "                    error condition is also different from the standard\n",
      "                    Cauchy matrix requirement (x[i] - y[j] != 0).\n",
      "    \"\"\"\n",
      "    # Incorrect logic: Using addition instead of subtraction.\n",
      "    # The standard Cauchy matrix requires np.subtract.outer(x, y).\n",
      "    # This common mistake fundamentally changes the calculation.\n",
      "    r = np.add.outer(x, y)\n",
      "\n",
      "    # Check for division by zero based on the *incorrect* intermediate result (x_i + y_j)\n",
      "    # This check itself is now inconsistent with the standard definition's requirement.\n",
      "    if np.sum(r == 0) > 0:\n",
      "        raise ValueError(\"incorrect check detected potential division by zero based on x + y\")\n",
      "\n",
      "    # The final computation uses the incorrect intermediate result 'r'.\n",
      "    # It calculates 1 / (x_i + y_j) instead of 1 / (x_i - y_j).\n",
      "    return 1 / r\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_start = a.find('<COUNTER_EXAMPLE>')+17\n",
    "f_end = a.find('</COUNTER_EXAMPLE>')\n",
    "\n",
    "counterexample_src = a[f_start:f_end]\n",
    "print(counterexample_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc232f-e5da-4a8c-b6c5-c89a8f1cbab3",
   "metadata": {},
   "source": [
    "## check manually counter example function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fa15bc2-7e86-4f04-b14e-b954106d455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modules/counterexample.py', 'w') as f:\n",
    "    f.write(counterexample_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fa200fe-e5c5-4a0a-a73f-aa8e4eebf691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import counterexample \n",
    "from importlib import reload\n",
    "reload(counterexample)\n",
    "import numpy as np\n",
    "x, y = np.random.random(size=(4)), np.random.random(size=(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "842e2a87-bff8-4b07-9569-05cb786a19d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(function(x,y),  eval(f'counterexample.{function_name}(x,y)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef5343a-a40e-4af2-b53d-d309834e0ef7",
   "metadata": {},
   "source": [
    "## run unittests with counterexamples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f35f57d-0fab-44e4-94aa-f409a3d28b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('file_with_tests.py') as f:\n",
    "    test_src = f.read()\n",
    "\n",
    "test_src = test_src.replace(f'from modules.{module_name}', 'from modules.counterexample')\n",
    "\n",
    "with open('file_with_tests_on_counterexamples.py', 'w') as f:\n",
    "    f.write(test_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "721d8644-0f91-43c5-b126-ac7d4827d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = [sys.executable, 'file_with_tests_on_counterexamples.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a694ad5-5983-4fc9-b694-7a11efbe58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(\n",
    "    command,\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    check=False, # Recommended to automatically check for errors\n",
    "    encoding='utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82f50141-7fea-4f02-bbbe-33a25a783e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f10f6339-7749-4a3a-af51-10a247faba18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".F.FFF\n",
      "======================================================================\n",
      "FAIL: test_cauchy_different_shapes (__main__.TestCauchyFunction.test_cauchy_different_shapes)\n",
      "Test cauchy function with inputs of different shapes.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raulramos/projects/genai-unittests/file_with_tests_on_counterexamples.py\", line 77, in test_cauchy_different_shapes\n",
      "    np.testing.assert_allclose(\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 1504, in assert_allclose\n",
      "    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 797, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Not equal to tolerance rtol=1e-05, atol=1e-08\n",
      "Different shapes case calculation failed.\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 0.375\n",
      "Max relative difference: 0.75\n",
      " x: array([[0.166667, 0.142857, 0.125   ]])\n",
      " y: array([[0.25    , 0.333333, 0.5     ]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_cauchy_scalar_like_input (__main__.TestCauchyFunction.test_cauchy_scalar_like_input)\n",
      "Test cauchy function with scalar-like numpy arrays.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raulramos/projects/genai-unittests/file_with_tests_on_counterexamples.py\", line 134, in test_cauchy_scalar_like_input\n",
      "    np.testing.assert_allclose(\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 1504, in assert_allclose\n",
      "    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 797, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Not equal to tolerance rtol=1e-05, atol=1e-08\n",
      "Scalar-like input case calculation failed.\n",
      "Mismatched elements: 1 / 1 (100%)\n",
      "Max absolute difference: 0.375\n",
      "Max relative difference: 0.75\n",
      " x: array([[0.125]])\n",
      " y: array([[0.5]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_cauchy_standard_case (__main__.TestCauchyFunction.test_cauchy_standard_case)\n",
      "Test cauchy function with valid inputs, no zero differences.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raulramos/projects/genai-unittests/file_with_tests_on_counterexamples.py\", line 49, in test_cauchy_standard_case\n",
      "    np.testing.assert_allclose(\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 1504, in assert_allclose\n",
      "    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 797, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Not equal to tolerance rtol=1e-05, atol=1e-08\n",
      "Standard case calculation failed.\n",
      "Mismatched elements: 4 / 4 (100%)\n",
      "Max absolute difference: 1.2\n",
      "Max relative difference: 1.6\n",
      " x: array([[0.25    , 0.2     ],\n",
      "       [0.2     , 0.166667]])\n",
      " y: array([[-0.5     , -0.333333],\n",
      "       [-1.      , -0.5     ]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_cauchy_zero_difference_error (__main__.TestCauchyFunction.test_cauchy_zero_difference_error)\n",
      "Test cauchy function raises ValueError when a difference is zero.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raulramos/projects/genai-unittests/file_with_tests_on_counterexamples.py\", line 63, in test_cauchy_zero_difference_error\n",
      "    with self.assertRaisesRegex(ValueError, \"division by zero\"):\n",
      "AssertionError: ValueError not raised\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.017s\n",
      "\n",
      "FAILED (failures=4)\n",
      ".F.FFF\n",
      "======================================================================\n",
      "FAIL: test_cauchy_different_shapes (__main__.TestCauchyFunction.test_cauchy_different_shapes)\n",
      "Test cauchy function with inputs of different shapes.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raulramos/projects/genai-unittests/file_with_tests_on_counterexamples.py\", line 77, in test_cauchy_different_shapes\n",
      "    np.testing.assert_allclose(\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 1504, in assert_allclose\n",
      "    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 797, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Not equal to tolerance rtol=1e-05, atol=1e-08\n",
      "Different shapes case calculation failed.\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 0.375\n",
      "Max relative difference: 0.75\n",
      " x: array([[0.166667, 0.142857, 0.125   ]])\n",
      " y: array([[0.25    , 0.333333, 0.5     ]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_cauchy_scalar_like_input (__main__.TestCauchyFunction.test_cauchy_scalar_like_input)\n",
      "Test cauchy function with scalar-like numpy arrays.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raulramos/projects/genai-unittests/file_with_tests_on_counterexamples.py\", line 134, in test_cauchy_scalar_like_input\n",
      "    np.testing.assert_allclose(\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 1504, in assert_allclose\n",
      "    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 797, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Not equal to tolerance rtol=1e-05, atol=1e-08\n",
      "Scalar-like input case calculation failed.\n",
      "Mismatched elements: 1 / 1 (100%)\n",
      "Max absolute difference: 0.375\n",
      "Max relative difference: 0.75\n",
      " x: array([[0.125]])\n",
      " y: array([[0.5]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_cauchy_standard_case (__main__.TestCauchyFunction.test_cauchy_standard_case)\n",
      "Test cauchy function with valid inputs, no zero differences.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raulramos/projects/genai-unittests/file_with_tests_on_counterexamples.py\", line 49, in test_cauchy_standard_case\n",
      "    np.testing.assert_allclose(\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 1504, in assert_allclose\n",
      "    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/contextlib.py\", line 81, in inner\n",
      "    return func(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/p312/lib/python3.12/site-packages/numpy/testing/_private/utils.py\", line 797, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Not equal to tolerance rtol=1e-05, atol=1e-08\n",
      "Standard case calculation failed.\n",
      "Mismatched elements: 4 / 4 (100%)\n",
      "Max absolute difference: 1.2\n",
      "Max relative difference: 1.6\n",
      " x: array([[0.25    , 0.2     ],\n",
      "       [0.2     , 0.166667]])\n",
      " y: array([[-0.5     , -0.333333],\n",
      "       [-1.      , -0.5     ]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_cauchy_zero_difference_error (__main__.TestCauchyFunction.test_cauchy_zero_difference_error)\n",
      "Test cauchy function raises ValueError when a difference is zero.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raulramos/projects/genai-unittests/file_with_tests_on_counterexamples.py\", line 63, in test_cauchy_zero_difference_error\n",
      "    with self.assertRaisesRegex(ValueError, \"division by zero\"):\n",
      "AssertionError: ValueError not raised\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.003s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a1ebe-bed9-4770-8c4e-0031669f07b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ee05c-056f-4697-8087-dfdcf92f3f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87d4d7-640d-4aa0-b379-0e31d8876dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e8cfcfa-62b4-421a-a630-63b0bf09a9df",
   "metadata": {},
   "source": [
    "# 4. run other quality checks on the tests\n",
    "\n",
    "## run test smells\n",
    "\n",
    "- https://github.com/maxpacs98/disertation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "69865bd8-3cd8-4f69-a048-ffce34985eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'check_assertion_roulette': 'ok',\n",
       " 'check_conditional_logic': 'ok',\n",
       " 'check_duplicate_assert': 'ok',\n",
       " 'check_eager_test': 'ok',\n",
       " 'check_exception_handling': 'ok',\n",
       " 'check_ignored_test': 'ok',\n",
       " 'check_magic_number': 'ok',\n",
       " 'check_redundant_print': 'ok',\n",
       " 'check_sleepy_test': 'ok',\n",
       " 'check_unknown_test': 'ok'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smells_functions = {i: eval(f'smells.{i}') for i in dir(smells) if i.startswith('check')}\n",
    "\n",
    "{k: \"ok\" if len(v(unittest_src))==0 else 'not_ok' for k,v in smells_functions.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1558f-8663-44a1-bbef-9a7ac6bb605e",
   "metadata": {},
   "source": [
    "## run `pylint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5e2ede30-e740-4182-840b-61c2b4ea4527",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylint_executable = \"/\".join(sys.executable.split('/')[:-1] + ['pylint'])\n",
    "command = [pylint_executable, 'file_with_tests.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e81f6359-dc59-467b-9c7b-7c7b75290ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    result = subprocess.run(\n",
    "        command,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        check=False, # Recommended to automatically check for errors\n",
    "        encoding='utf-8'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0bdb9193-a9bc-41e0-8098-d1da321fadb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Module file_with_tests\n",
      "file_with_tests.py:150:0: C0304: Final newline missing (missing-final-newline)\n",
      "file_with_tests.py:47:4: W0404: Reimport 'numpy' (imported line 4) (reimported)\n",
      "file_with_tests.py:47:4: C0412: Imports from package numpy are not grouped (ungrouped-imports)\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Your code has been rated at 9.43/10 (previous run: 7.92/10, +1.52)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e2f9091c-8db7-4238-9111-0677163bbfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503b246-75b8-4077-aa94-54920949d7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312 (Local)",
   "language": "python",
   "name": "p312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
